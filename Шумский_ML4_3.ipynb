{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6kbFOsnYRlak"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Загрузите датасет ирисы Фишера из библиотеки sklearn.datasets."
      ],
      "metadata": {
        "id": "b67_5ZOXJGBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X, y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiiH1Fji8eJp",
        "outputId": "8a3d1804-4728-408e-8196-9a4e18a739da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Сделайте hold-out разбиение данных. Для этого разделите данные на обучающую и валидационную выборки и выведите на экран соответствующие индексы разбиения."
      ],
      "metadata": {
        "id": "zO2-iJODJj4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Получение индексов обучающей и валидационной выборок\n",
        "train_indexes = X_train.index if hasattr(X_train, 'index') else range(len(X_train))\n",
        "validation_indexes = X_validation.index if hasattr(X_validation, 'index') else range(len(X_train), len(X_train) + len(X_validation))\n",
        "\n",
        "train_indexes, validation_indexes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mzof_8Y82pP",
        "outputId": "2e95f49c-39df-4e1c-e772-ab5524882257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(range(0, 120), range(120, 150))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3. Теперь сделайте разбиение перемешанных данных, зафиксировав воспроизводимость выбора данных после перемешивания, указав значение параметра random_state=42 и выведите на экран соответствующие индексы разбиения."
      ],
      "metadata": {
        "id": "2WihM3noLJf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_shuffled, X_validation_shuffled, y_train_shuffled, y_validation_shuffled = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# Поскольку индексы не доступны напрямую (данные являются numpy массивами), используем альтернативный способ определения индексов через mask\n",
        "# Создадим полный массив индексов\n",
        "full_indexes = range(len(X))\n",
        "\n",
        "# Находим обучающие индексы как те, которые не в валидационном наборе, и наоборот\n",
        "train_mask = np.isin(full_indexes, train_indexes, invert=True)\n",
        "validation_mask = np.isin(full_indexes, validation_indexes)\n",
        "\n",
        "# Получаем исходные индексы для перемешанных выборок\n",
        "train_shuffled_indexes = np.array(full_indexes)[train_mask]\n",
        "validation_shuffled_indexes = np.array(full_indexes)[validation_mask]\n",
        "\n",
        "train_shuffled_indexes, validation_shuffled_indexes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUzvJXWW9JjA",
        "outputId": "71b33ea0-faa6-4004-9324-6cf8e6194b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "        146, 147, 148, 149]),\n",
              " array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "        146, 147, 148, 149]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Обучите модель логистической регрессии на обучающих данных. Выведите значения коэффициентов модели, полученных в результате обучения. Сделайте предсказание на тестовом наборе признаков. Выведите значение метрик accuracy и f1-score."
      ],
      "metadata": {
        "id": "1DckOFSfs42P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model.fit(X_train_shuffled, y_train_shuffled)\n",
        "\n",
        "coefficients = model.coef_\n",
        "\n",
        "y_pred = model.predict(X_validation_shuffled)\n",
        "\n",
        "accuracy = accuracy_score(y_validation_shuffled, y_pred)\n",
        "f1 = f1_score(y_validation_shuffled, y_pred, average='macro')\n",
        "\n",
        "print(\"Коэффициенты модели логистической регрессии:\\n\")\n",
        "classes = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
        "for index, class_name in enumerate(classes):\n",
        "    print(f\"{class_name}: {coefficients[index]}\")\n",
        "print(\"\\nМетрики на валидационном наборе данных:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1-Score (macro): {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVXS8w5F9qcg",
        "outputId": "5a232655-5ade-493d-af2b-e30d6f605ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коэффициенты модели логистической регрессии:\n",
            "\n",
            "Iris-setosa: [ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
            "Iris-versicolor: [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
            "Iris-virginica: [-1.55895271 -1.58893375  2.39874554  2.15556209]\n",
            "\n",
            "Метрики на валидационном наборе данных:\n",
            "Accuracy: 1.0000\n",
            "F1-Score (macro): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5. Разделите данные на обучающую и валидационную выборки по новому в соотношении 75-25. Обучите модель на этих данных, выведите значения получившихся коэффициентов модели. Выведите значения метрик и сравните их со значениями из предыдущего пункта. Сделайте вывод о том, влияет ли способ разбиения на результат."
      ],
      "metadata": {
        "id": "2anfgXIgs5MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_new, X_validation_new, y_train_new, y_validation_new = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "model_new = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model_new.fit(X_train_new, y_train_new)\n",
        "\n",
        "coefficients_new = model_new.coef_\n",
        "\n",
        "y_pred_new = model_new.predict(X_validation_new)\n",
        "\n",
        "accuracy_new = accuracy_score(y_validation_new, y_pred_new)\n",
        "f1_new = f1_score(y_validation_new, y_pred_new, average='macro')\n",
        "\n",
        "print(\"Коэффициенты модели логистической регрессии после нового разбиения данных (75-25):\\n\")\n",
        "for index, class_name in enumerate(classes):\n",
        "    print(f\"{class_name}: {coefficients_new[index]}\")\n",
        "print(\"\\nМетрики на новом валидационном наборе данных:\")\n",
        "print(f\"Accuracy: {accuracy_new:.4f}\")\n",
        "print(f\"F1-Score (macro): {f1_new:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIvz4hDw_Iwo",
        "outputId": "90c888a1-c1aa-4bed-fcbf-e8ac770481d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коэффициенты модели логистической регрессии после нового разбиения данных (75-25):\n",
            "\n",
            "Iris-setosa: [ 0.37199402  1.3721129  -2.12209543 -0.93577108]\n",
            "Iris-versicolor: [ 0.46579126 -1.55972584  0.41868466 -1.08288284]\n",
            "Iris-virginica: [-1.55311025 -1.5151226   2.36636048  2.1109172 ]\n",
            "\n",
            "Метрики на новом валидационном наборе данных:\n",
            "Accuracy: 1.0000\n",
            "F1-Score (macro): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изменение соотношения разбиения данных на обучающую и валидационную выборки не оказало заметного влияния на результаты классификации модели логистической регрессии в данном случае."
      ],
      "metadata": {
        "id": "clCvAwTp_d8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####6. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию). Сравните полученные метрики с метриками, которые были при hold-out разбиении."
      ],
      "metadata": {
        "id": "xNmDs50Ts60-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model_cv = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "\n",
        "# Выполнение k-блочной перекрёстной проверки для метрики accuracy\n",
        "cv_accuracy = cross_val_score(model_cv, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Выполнение k-блочной перекрёстной проверки для метрики f1-score с усреднением по макро\n",
        "cv_f1 = cross_val_score(model_cv, X, y, cv=5, scoring='f1_macro')\n",
        "\n",
        "cv_accuracy_mean = np.mean(cv_accuracy)\n",
        "cv_f1_mean = np.mean(cv_f1)\n",
        "\n",
        "cv_accuracy_mean, cv_f1_mean\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQ_v7i-_QLe",
        "outputId": "59028fc3-5a74-46d8-b6d9-b0e0fc875331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9600000000000002, 0.959522933505973)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "При предыдущем hold-out разбиении данных мы получили идеальные значения метрик (Accuracy и F1-Score) равные 1.0. В случае кросс-валидации, значения метрик немного ниже, но всё же очень высоки."
      ],
      "metadata": {
        "id": "Ki5Cr4KIAKvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кросс-валидация предоставляет более обобщенную оценку качества модели, так как данные оцениваются на нескольких разбиениях, а результаты усредняются. Это уменьшает влияние конкретного разбиения данных на оценку модели и предоставляет более надежную оценку её способности к обобщению на новых данных."
      ],
      "metadata": {
        "id": "6k2zWuesALlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####7. Теперь сделайте ту же самую перекрёстную проверку модели, используя библиотечную функцию cross_val_score. Убедитесь, что получится тот же результат."
      ],
      "metadata": {
        "id": "4gu9uDGN8oHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_accuracy_repeat = cross_val_score(model_cv, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "cv_f1_repeat = cross_val_score(model_cv, X, y, cv=5, scoring='f1_macro')\n",
        "\n",
        "cv_accuracy_mean_repeat = np.mean(cv_accuracy_repeat)\n",
        "cv_f1_mean_repeat = np.mean(cv_f1_repeat)\n",
        "\n",
        "cv_accuracy_mean_repeat, cv_f1_mean_repeat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpd6qkaUAlhc",
        "outputId": "2ce0ad3a-1147-40fb-f760-f9c4742e1be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9600000000000002, 0.959522933505973)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это подтверждает надёжность и воспроизводимость результатов кросс-валидации с использованием библиотечной функции. Полученные метрики согласуются с предыдущими значениями, что демонстрирует высокое качество модели и её способность к обобщению на новых данных."
      ],
      "metadata": {
        "id": "StwBAQTGAr7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####8. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию) со стратификацией. Проделайте всё тоже самое, что и в предыдущем пункте."
      ],
      "metadata": {
        "id": "RuE3x66k8oui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "cv_stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_accuracy_stratified = cross_val_score(model_cv, X, y, cv=cv_stratified, scoring='accuracy')\n",
        "\n",
        "cv_f1_stratified = cross_val_score(model_cv, X, y, cv=cv_stratified, scoring='f1_macro')\n",
        "\n",
        "cv_accuracy_stratified_mean = np.mean(cv_accuracy_stratified)\n",
        "cv_f1_stratified_mean = np.mean(cv_f1_stratified)\n",
        "\n",
        "cv_accuracy_stratified_mean, cv_f1_stratified_mean\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY3gDbnjAuQ_",
        "outputId": "8e41eefb-cfc1-4b6e-f4aa-e5f80bffc41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.96, 0.959522933505973)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Значения метрик остались такими же, как и при обычной кросс-валидации без стратификации, что указывает на стабильность модели и её способность к обобщению на новых данных, независимо от метода разбиения."
      ],
      "metadata": {
        "id": "MgE2GBvzA93L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####9. Теперь сделайте перекрёстную проверку, изпользуя leave-one-out разбиение. Проделайте всё тоже самое, что и в предыдущем пункте."
      ],
      "metadata": {
        "id": "S2kqpUL78pCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# Создание разбиения leave-one-out\n",
        "cv_loo = LeaveOneOut()\n",
        "\n",
        "cv_accuracy_loo = cross_val_score(model_cv, X, y, cv=cv_loo, scoring='accuracy')\n",
        "\n",
        "cv_f1_loo = cross_val_score(model_cv, X, y, cv=cv_loo, scoring='f1_macro')\n",
        "\n",
        "cv_accuracy_loo_mean = np.mean(cv_accuracy_loo)\n",
        "cv_f1_loo_mean = np.mean(cv_f1_loo)\n",
        "\n",
        "cv_accuracy_loo_mean, cv_f1_loo_mean\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2qV67o-BJ0A",
        "outputId": "cdb401f1-c67d-47f8-a583-a45487eb5a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9533333333333334, 0.9533333333333334)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Значения метрик немного ниже, чем при использовании стратифицированной и нестратифицированной k-блочной перекрёстной проверки (где оба показателя были равны 0.96)."
      ],
      "metadata": {
        "id": "FAIoLO-fBPYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод leave-one-out предоставляет один из самых строгих способов кросс-валидации, поскольку модель обучается на всех данных, кроме одного элемента, а затем тестируется на этом единственном элементе. Это процесс повторяется для каждого элемента в наборе данных. Такой подход может быть более чувствителен к выбросам и шуму в данных, что может объяснить незначительное снижение метрик по сравнению с другими методами кросс-валидации. Несмотря на это, полученные результаты всё ещё указывают на высокую эффективность модели. ​"
      ],
      "metadata": {
        "id": "Fzu1FM13BTg1"
      }
    }
  ]
}